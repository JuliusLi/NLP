{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Analysis Assignment 5: Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Information\n",
    "Please fill in the following information:\n",
    "\n",
    "- **Name**:    [You Li]\n",
    "\n",
    "- **Uni id**:  [u6430173]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this assignment, the task is to code a Named Entity Recognizer (NER) application in Python using the CRFsuite library.\n",
    "\n",
    "To complete this task, follow the tutorial NamedEntityExtraction.ipynb and the ie-assignment-instructions.ipynb instructions posted in Wattle.\n",
    "\n",
    "The following items summaries the assigment tasks:\n",
    "1. Built a NER classifier following the tutorial.\n",
    "2. Write a Python NER application that used your classifier.\n",
    "3. Submit your results in Kaggle.\n",
    "3. Answerd three written assignments.\n",
    "\n",
    "\n",
    "* We will check the correctness of your code, but the score of the programming assignments will be graded based on your performance on Kaggle competition.\n",
    "* Write your code after ### Your code here, and remove raise NotImplementedError after implementation.\n",
    "* Written assignments should be written in the given notebook cells. Please write them direcly in to the designated cells, and upload the notebook file to Wattle page.\n",
    "* Write answers in this notebook file, and upload the file to Wattle submission site. **Please rename and submit jupyter notebook file (Assignment5.ipynb) to your_uid.ipynb (e.g. u6000001.ipynb) with your written answers therein**. Do not upload any other files to Wattle except this notebook file.\n",
    "\n",
    "\n",
    "## For the Kaggle competition\n",
    "\n",
    "Join the competition [here](https://www.kaggle.com/t/8cedc437b8d84b8f8710ecb74e96e349).\n",
    "Before submitting the result, first go to team menu and change your team name as your university id.\n",
    "You need to upload the generated result file to Kaggle. \n",
    "\n",
    "Note that you are only allowed to upload 5 copies of your results to Kaggle per day. Make every upload count, and don't waste your opportunities!\n",
    "You should use cross-validation instead of relying on the public set - this is what the daily limit is for!\n",
    "**Note:** you need to fill in the cells below with your code. Failure to provide your code nullifies your Kaggle grade (meaning you get zero for the coding part)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build a NER model (4 points) <a id='Task1'></a>\n",
    "\n",
    "* You can use the code provided in [tutorial sheet](Tutorial/Named_Entity_Extraction_Tutorial.ipynb) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version: 0.19.1\n",
      "Libraries succesfully loaded!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import io\n",
    "import nltk\n",
    "import scipy\n",
    "import codecs\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "# import enchant\n",
    "# from langdetect import DetectorFactory \n",
    "\n",
    "print('sklearn version:', sklearn.__version__)\n",
    "print('Libraries succesfully loaded!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data\n",
    "train_data, train_ids = extract_data('train')\n",
    "test_data, test_ids = extract_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent, feature_func):\n",
    "    return [feature_func(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    #print('sent', sent)\n",
    "    return [s[-1] for s in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [s[0] for s in sent]\n",
    "\n",
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(y_true)\n",
    "    y_pred_combined = lb.transform(y_pred)\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )\n",
    "# load data and preprocess\n",
    "def extract_data(path):\n",
    "    \"\"\"\n",
    "    Extracting data from train file or test file. \n",
    "    path - the path of the file to extract\n",
    "    \n",
    "    return:\n",
    "        res - a list of sentences, each sentence is a\n",
    "              a list of tuples. For train file, each tuple\n",
    "              contains token and label. For test file, each\n",
    "              tuple only contains token.\n",
    "        ids - a list of ids for the corresponding token. This\n",
    "              is mainly for Kaggle submission.\n",
    "    \"\"\"\n",
    "    #with open(path) as file:\n",
    "    file = io.open(path, mode=\"r\", encoding=\"utf-8\")\n",
    "    next(file)\n",
    "    res = []\n",
    "    ids = []\n",
    "    sent = []\n",
    "    for line in file:\n",
    "        if line != '\\n':\n",
    "            parts = line.strip().split(' ')\n",
    "            sent.append(tuple(parts[1:]))\n",
    "            ids.append(parts[0])\n",
    "        else:\n",
    "            res.append(sent)\n",
    "            sent = []\n",
    "                \n",
    "    return res, ids\n",
    "\n",
    "# english_dict = enchant.Dict(\"en_US\") #also available are en_GB, fr_FR, etc\n",
    "\n",
    "# english_dict.check(\"Hello\") # prints True\n",
    "# english_dict.check(\"Helo\") #prints False\n",
    "            \n",
    "def word2simple_features(sent, i):\n",
    "    '''\n",
    "    This makes a simple baseline.  \n",
    "    You can add and/or remove features to get (much?) better results.\n",
    "    Experiment with it as you will need to do this for assignment.\n",
    "    '''\n",
    "    word = sent[i][0]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-4:]': word[-4:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "#         'word.isEnglish()': english_dict.check(word)\n",
    "    }\n",
    "    if i == 0:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    if i == len(sent)-1:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test data upload succesfully!\n",
      "Feature Extraction done!\n"
     ]
    }
   ],
   "source": [
    "print('Train and Test data upload succesfully!')\n",
    "\n",
    "# Feature extraction using the word2simple_features function\n",
    "train_features = [sent2features(s, feature_func=word2simple_features) for s in train_data]\n",
    "train_labels = [sent2labels(s) for s in train_data]\n",
    "test_features = [sent2features(s, feature_func=word2simple_features) for s in test_data]\n",
    "\n",
    "# print (train_features)\n",
    "\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "for xseq, yseq in zip(train_features, train_labels):\n",
    "    trainer.append(xseq, yseq)\n",
    "print('Feature Extraction done!')    \n",
    "\n",
    "# Explore the extracted features    \n",
    "# sent2features(train_data[0], word2simple_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'calibration.eta',\n",
       " 'calibration.rate',\n",
       " 'calibration.samples',\n",
       " 'calibration.candidates',\n",
       " 'calibration.max_trials']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.select('l2sgd')\n",
    "trainer.params()\n",
    "#, 'lbfgs', 'l2sgd', 'ap', 'pa', 'arow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'feature.minfreq': 0,\n",
    "#     'feature.possible_states': 8,\n",
    "#     'c1': 0.01,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "    'calibration.rate': 0.01,\n",
    "    'calibration.samples': 10,\n",
    "\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': False\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done :)\n",
      "CPU times: user 13.2 s, sys: 271 ms, total: 13.4 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train('ner-esp.model')\n",
    "\n",
    "print('Training done :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x1a0cc82150>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('ner-esp.model')\n",
    "\n",
    "# from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     train_features, train_labels, test_size=0.2, random_state=1)\n",
    "# y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "\n",
    "# y_test = [item for sublist in y_test for item in sublist]\n",
    "# y_pred = [item for sublist in y_pred for item in sublist]\n",
    "# print(bio_classification_report(y_pred, y_test))\n",
    "\n",
    "# import numpy as np\n",
    "# X = np.array(train_features)\n",
    "# y = np.array(train_labels)\n",
    "# kf = KFold(n_splits=2)\n",
    "# kf.get_n_splits(X)\n",
    "# KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "# y_test = [item for sublist in y_test for item in sublist]\n",
    "# y_pred = [item for sublist in y_pred for item in sublist]\n",
    "# print(bio_classification_report(y_pred, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the above cell should look something like this (ignored the numbers)\n",
    "\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "      B-LOC       0.68      0.47      0.55      1084\n",
    "      I-LOC       0.52      0.25      0.34       325\n",
    "     B-MISC       0.54      0.11      0.19       339\n",
    "     I-MISC       0.54      0.22      0.32       557\n",
    "      B-ORG       0.76      0.51      0.61      1400\n",
    "      I-ORG       0.67      0.44      0.53      1104\n",
    "      B-PER       0.73      0.68      0.71       735\n",
    "      I-PER       0.78      0.82      0.80       634\n",
    "\n",
    "avg / total       0.68      0.48      0.55      6178\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate your result file for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kaggle_res_file(ids, labels, file_path):\n",
    "    \"\"\"\n",
    "    Generate result file for submitting to Kaggle.\n",
    "    ids - the id for the tokens in test file\n",
    "          should be in the same order as test file\n",
    "    labels - the predictted label for each token\n",
    "    file_path - the path includes the filename where\n",
    "                you want to save the result\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w') as res_file:\n",
    "        res_file.write('id,label\\n')\n",
    "        for i,l in zip(ids, labels):\n",
    "            res_file.write('{},{}\\n'.format(i,l))\n",
    "            \n",
    "test_pred = [tagger.tag(xseq) for xseq in test_features]\n",
    "# print(len(test_pred)) #3232\n",
    "test_pred = [s for w in test_pred for s in w]\n",
    "# print(len(test_pred)) #110973 split up\n",
    "\n",
    "\n",
    "# Generate Kaggle file\n",
    "generate_kaggle_res_file(test_ids, test_pred, 'result.csv')\n",
    "\n",
    "## Print evaluation\n",
    "# true_labels = [item for sublist in train_labels for item in sublist]\n",
    "\n",
    "# print(bio_classification_report(test_pred, test_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 {'loss': 5923.742288, 'num': 50, 'time': 0.268, 'scores': {}}\n"
     ]
    }
   ],
   "source": [
    "print (len(trainer.logparser.iterations), trainer.logparser.iterations[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "I-PER  -> I-PER   21.371134\n",
      "B-PER  -> I-PER   20.847619\n",
      "B-LOC  -> I-LOC   18.044348\n",
      "I-LOC  -> I-LOC   17.475985\n",
      "B-ORG  -> I-ORG   15.658785\n",
      "I-MISC -> I-MISC  15.579910\n",
      "I-ORG  -> I-ORG   15.215636\n",
      "B-MISC -> I-MISC  14.864139\n",
      "O      -> B-MISC  11.301012\n",
      "O      -> B-PER   11.285724\n",
      "O      -> B-ORG   11.277918\n",
      "O      -> O       8.282484\n",
      "O      -> B-LOC   7.180390\n",
      "B-LOC  -> B-LOC   6.751599\n",
      "I-PER  -> B-PER   6.494097\n",
      "\n",
      "Top unlikely transitions:\n",
      "I-ORG  -> B-MISC  0.168685\n",
      "B-PER  -> B-LOC   0.167065\n",
      "B-PER  -> O       -0.208186\n",
      "I-LOC  -> O       -0.391371\n",
      "B-ORG  -> O       -1.109475\n",
      "B-MISC -> O       -1.457623\n",
      "B-MISC -> B-LOC   -1.493944\n",
      "I-LOC  -> B-LOC   -1.832502\n",
      "I-MISC -> O       -1.886312\n",
      "I-ORG  -> O       -2.481942\n",
      "B-LOC  -> B-ORG   -2.545534\n",
      "I-MISC -> B-LOC   -2.797817\n",
      "B-PER  -> B-PER   -2.992206\n",
      "I-ORG  -> B-LOC   -4.157652\n",
      "B-ORG  -> B-ORG   -5.102596\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "info = tagger.info()\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common(15))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common()[-15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "20.727089 O      word.lower():o\n",
      "19.351184 B-ORG  word.lower():bnp-paribas\n",
      "19.144133 I-MISC word.lower():extraviado\n",
      "19.068087 O      word[-2:]:73\n",
      "18.948370 B-ORG  word.lower():psoe-progresistas\n",
      "18.944462 B-MISC word.lower():firagran\n",
      "18.560838 I-MISC word.lower():firagran\n",
      "18.545395 B-ORG  word.lower():efe-cantabria\n",
      "17.190828 B-MISC word.lower():life-naturaleza\n",
      "17.100157 B-ORG  word[-2:]:-e\n",
      "16.875733 B-LOC  word.lower():baleares\n",
      "16.397091 I-ORG  word.lower():barbara\n",
      "16.362945 B-ORG  word.lower():coag-extremadura\n",
      "16.211379 B-ORG  word.lower():eu-ecologista\n",
      "15.786045 B-ORG  word.lower():petrobras\n",
      "15.226565 B-ORG  word.lower():alcampo\n",
      "15.204431 I-LOC  word.lower():rose\n",
      "15.085947 B-PER  word.lower():mcmanaman\n",
      "14.235392 B-ORG  word.lower():gestion\n",
      "14.036794 O      word.lower():amistad\n",
      "\n",
      "Top negative:\n",
      "-5.692406 O      word.lower():sudeste\n",
      "-5.752065 O      word.lower():humanos\n",
      "-5.762225 O      word.lower():convento\n",
      "-5.791521 O      word.lower():agricultura\n",
      "-5.813972 O      word.lower():derechos\n",
      "-5.979357 I-PER  bias\n",
      "-5.997948 O      word[-3:]:sil\n",
      "-6.024342 O      word.lower():noticias\n",
      "-6.437890 O      word.lower():puente\n",
      "-6.694158 O      word.lower():palabra\n",
      "-6.774642 O      word.lower():tareas\n",
      "-7.044956 O      word.lower():mental\n",
      "-7.603020 O      word.lower():061\n",
      "-7.960011 O      word[-2:]:nd\n",
      "-8.388094 O      word.lower():bosque\n",
      "-8.527959 O      word.lower():valido\n",
      "-8.606823 O      word.isupper()\n",
      "-8.691037 O      word.lower():duques\n",
      "-11.610026 O      word[-2:]:om\n",
      "-12.017362 O      word.istitle()\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-6s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(info.state_features).most_common(20))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(info.state_features).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Written part (6 pts)\n",
    "\n",
    "Answer briefly and concisely the following questions.\n",
    "Provide answers using bullet list with 2~3 items.\n",
    "Check [this](https://sourceforge.net/p/jupiter/wiki/markdown_syntax/#md_ex_lists) if you are not familiar with markdown syntax.\n",
    "Each questions is worth 1 mark (10%) of the total grade for the IE assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (2 pts)\n",
    "Think about three relevant baselines for the Named Entity Classification task.\n",
    "Provide answers using bullet list with 3 items. Give a short description of each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline is defined as the information that used as a starting point bt which to compare other information.\n",
    "In benchmarking, the baseline describes the simple approaches of the selected learning methods. Overall, it including random word assignment, majority class voting, heuristics, machine learning methods, and simple feature sets.\n",
    "\n",
    "* The first baseline is knowledge based feature sets. In this specific NER Classification task, The first baseline implements a knowledge-based approach and is based on a set of dictionaries and hand-crafted rules. In word2simple_features function, word identity, word suffix, word shape and word POS tag (label) were used for train the model.\n",
    "\n",
    "* The second baseline implements a statistical approach on features extracted. In this machine-learning system, namely a linear-chain conditional random field (CRF) with Viterbi inference that uses full corpus statistics. Cross-validation over the markup of the corpus was performed in training the data set.\n",
    "\n",
    "* The third baseline is implementing suitable algorithms and parameters for training the model. Multiple training algorithms were built for train the learning model, including lbfgs, l2sgd, ap, pa, and arow which delivers different performance. Changing the parameters for each model also provides variety of training results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (2 pts)\n",
    "How the Maximal Marginal Relevance (MMR) addresses redundancy issues? (1 point)\n",
    "How can you tell MMR that \"Sydney\" and \"Melbourne\" are cities? (0.5 points)\n",
    "How can you tell MMR that \"solar panels\" and \"photovoltaic cells\" have similar meaning? (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* According to Carbonell & Goldstein, 1998, the Maximal Marginal Relevance, MMR is defines as follow:\n",
    "\n",
    "$$\n",
    "M M R \\stackrel { \\mathrm { def } } { = } \\operatorname { arg } \\max _ { D _ { i } \\in R \\backslash S } \\left[ \\lambda \\left( \\operatorname { Sim } _ { 1 } \\left( D _ { i } , Q \\right) - ( 1 - \\lambda ) \\max _ { D _ { j } \\in S } \\operatorname { sim } _ { 2 } \\left( D _ { i } , D _ { j } \\right) \\right) \\right]\n",
    "$$\n",
    "Where \n",
    "\n",
    "Given the above definition, MMR computes incrementally the standard relevance-ranked list when the parameter $\\lambda=1$, and computes a maximal diversity ranking among the documents in R when $\\lambda=0$. This is a linear combination of both criteria is optimized. Users wishing to sample the information space around the query, should set $\\lambda$ closer to 0; in contrast, if users want focus on multiple potentially overlapping or reinforcing relevant documents, should set $\\lambda$ closer to 1. In other words, the redundancy has strong relation with $\\lambda$.\n",
    "\n",
    "\n",
    "* In the above definition, $Sim1$ measures the relevance between an item and a query. Hence it could be done by difining ontological relations of Sydney and Mulburn as instances of city. Besides, defining words with first capitalised or Gazzeters could be useful. This word relation could be to the ranked list $R$. However this is an ambiguity prolblems of words with upper case.\n",
    "\n",
    "* In the above definition, $Sim2$ measures the relevance between between two items. The items \"solar panels\" and \"photovoltaic cells\" have synonym relation of \"solar\" and \"photovoltaic\", and the word root as \"sol-\" and \"photo-\". \"sol-\" related \"sun\" word family:  helio-, and \"photo-\" Etymologically related \"light, shine, glow\" word families: \n",
    " ethero-;\n",
    " helio-.\n",
    " lustr-; \n",
    " phengo-; \n",
    " pheno-; \n",
    " phospho-;\n",
    " scinti-, scintill-;\n",
    " splendo-.\n",
    "So the connection could be built by set realations of word roots, and send the word relation to the ranked list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (2 pts)\n",
    "\n",
    "Imagine you are developing an extractive text summarization tool using HMM.\n",
    "What are the hidden states and the observations of the HMM model?\n",
    "Which algorithm is use to compute the prob. of a particular observation sequence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"HMM.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The HMM model is shown as above.\n",
    "    * $Q = q _ { 1 } q _ { 2 } \\dots q _ { N } \\quad$ a set of $N$ states\n",
    "\n",
    "    * $A = a _ { 11 } \\ldots a _ { i j } \\ldots a _ { N N } \\quad$ a transition probability matrix $A ,$ each $a _ { i j }$ representing the probability of moving from state $i$ to state $j \\\\$ s.t. $\\sum _ { j = 1 } ^ { N } a _ { i j } = 1 \\quad \\forall i$\n",
    "\n",
    "    * $O = o _ { 1 } o _ { 2 } \\ldots o _ { T } \\quad$ a sequence of T observations, each one drawn from a vocabulary $V =v _ { 1 } , v _ { 2 } , \\dots , v _ { V }$\n",
    "\n",
    "    * $B = b _ { i } \\left( o _ { t } \\right) \\quad$ a sequence of observation likelihoods, also called emission probabilities, each expressing the probability of an observation $o _ { t }$ being generated from a state $i$\n",
    "\n",
    "    * $\\pi = \\pi _ { 1 } , \\pi _ { 2 } , \\ldots , \\pi _ { N } \\quad$ an initial probability distribution over states. $\\pi _ { i }$ is the probability that the Markov chain will start in state i. Some states j may have $\\pi _ { j } = 0$, meaning that they cannot be initial states. Also, $\\sum _ { i = 1 } ^ { n } \\pi _ { i } = 1$\n",
    "\n",
    "* Hidden states is the set Q of X and observations is the sequence of O.\n",
    "\n",
    "    * To illustrate, in the problem of icecream weather, set Q of H-H-C is hidden state and set O of 3-3-1 is the observations.\n",
    "\n",
    "* Viterbi algorithm is used for decoding problems for HMM. \n",
    "\n",
    "    * This is an Dynamic programming algorithm, use trellis to store probabilities that the HMM is in state $j$ after seeing the first $t$ observations, for all states $j$. Best path Extension of a path from state $i$ at time $t-1$ is computed.\n",
    "$$\n",
    "v _ { t } ( j ) = \\max _ { i = 1 } v _ { t - 1 } ( i ) a _ { i j } b _ { j } \\left( o _ { t } \\right)\n",
    "$$\n",
    "To illustrate, following image shows the process of Viterbi. In each state, posiboity of H/F were calculated accordign to transition parameters A and emission parameters B. Then the move is made from the node with highest value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Viterbi.png\">\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
